{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function, unicode_literals\n",
    "import requests\n",
    "import pymongo\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connection = pymongo.MongoClient(\"mongodb://localhost\")\n",
    "ershou_col = connection.cq.lianjia_ershou_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 装载所有id\n",
    "ershou_set = set()\n",
    "for i in ershou_col.find({},{\"_id\":1}):\n",
    "    ershou_set.add(i[\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/levenls/Downloads/chromedriver')\n",
    "driver.get(\"http://cq.lianjia.com/ershoufang/106091601340.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_pattern = re.compile(\"<span.+span>\")\n",
    "brackets_ptr = re.compile(\"\\(.+\\)\")\n",
    "id_pattern = re.compile(r\"/[0-9]+.html\")\n",
    "base_url = \"https://cq.lianjia.com/ershoufang/pg{0}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_house_details(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    h_d = {}\n",
    "    h_d[\"_id\"] = re.search(id_pattern, url).group(0).replace(\"/\", \"\").replace(\".html\", \"\")\n",
    "    h_d[\"title\"] = soup.find(\"h1\")[\"title\"]\n",
    "    h_d[\"desc\"] = soup.find(\"div\", class_=\"sub\")[\"title\"]\n",
    "    h_d[\"total_price\"] = float(soup.find(\"div\", class_=\"price\").find(\"span\", class_=\"total\").get_text())\n",
    "    h_d[\"unit_price\"] = soup.find(\"div\", class_=\"unitPrice\").get_text()\n",
    "    h_d[\"tax\"] = soup.find(\"span\", class_=\"taxtext\").get_text()\n",
    "    base_info = soup.find(\"div\", class_=\"base\").find_all(\"li\")\n",
    "    for i in base_info:\n",
    "        tmp = i.find(\"span\").get_text().strip()\n",
    "        if tmp == u\"\\u6240\\u5728\\u697c\\u5c42\":\n",
    "            h_d[\"floor\"] = re.sub(brackets_ptr, \"\", i.get_text().replace(tmp, \"\")).strip()\n",
    "            h_d[\"total_floor\"] = re.search(brackets_ptr, i.get_text().replace(tmp, \"\")).group(0).replace(\"(\", \"\").replace(\")\",\"\")\n",
    "            continue\n",
    "        h_d[tmp] = i.get_text().replace(tmp, \"\").strip()\n",
    "        \n",
    "    trade_info = soup.find(\"div\", class_=\"transaction\").find_all(\"li\")\n",
    "    for i in trade_info:\n",
    "        tmp = i.find(\"span\").get_text().strip()\n",
    "        h_d[tmp] = i.get_text().replace(tmp, \"\").strip()\n",
    "        \n",
    "    h_d[\"area\"] = \",\".join([i.get_text() for i in soup.find(\"div\", class_=\"areaName\").find_all(\"a\")])\n",
    "    h_d[\"community_id\"] = soup.find(\"div\", class_=\"communityName\").find(\"a\")[\"href\"].split(\"/\")[-2]\n",
    "    h_d[\"community_name\"] = soup.find(\"div\", class_=\"communityName\").find(\"a\").get_text()\n",
    "    \n",
    "    ex_info = soup.find_all(\"div\", class_=\"introContent\")[1].find_all(\"div\", class_=\"baseattribute\")\n",
    "    for i in ex_info:\n",
    "        tmp = i.find(\"div\", class_=\"name\").get_text().replace(\"\\n\", \"\").strip()\n",
    "        h_d[tmp] = i.find(\"div\", class_=\"content\").get_text().replace(\"\\n\", \"\").strip()\n",
    "\n",
    "    h_d[\"total_viewed\"] = int(soup.find(\"div\", class_=\"totalCount\").find(\"span\").get_text())\n",
    "    ershou_col.insert_one(h_d)\n",
    "    print (\"录入了一套房: {0}\".format(h_d[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in log_progress(range(1, 101)):\n",
    "    time.sleep(random.uniform(1.5,3.5))\n",
    "    driver.get(base_url.format(i))\n",
    "    rsoup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    for c in rsoup.find(\"ul\", class_=\"sellListContent\"):\n",
    "        house_url = c.find(\"a\")[\"href\"]\n",
    "        house_id = re.search(id_pattern, house_url).group(0).replace(\"/\", \"\").replace(\".html\", \"\")\n",
    "\n",
    "        # record_view\n",
    "        record_view = {}\n",
    "        folinfo = c.find(\"div\", class_=\"followInfo\").get_text()\n",
    "        record_view[\"interested\"] = folinfo.split(\"/\")[0].strip().replace(u\"\\u4eba\\u5173\\u6ce8\", \"\")\n",
    "        record_view[\"viewed\"] = folinfo.split(\"/\")[1].strip().replace(u\"\\u5171\",\"\").replace(u\"\\u6b21\\u5e26\\u770b\",\"\")\n",
    "        record_view[\"post_date\"] = folinfo.split(\"/\")[2].strip()\n",
    "        record_view[\"spider_data\"] = datetime.datetime.utcnow()\n",
    "        view_col.insert_one(record_view)\n",
    "\n",
    "        if house_id not in ershou_set:\n",
    "            get_house_details(house_url)\n",
    "            ershou_set.add(house_id)\n",
    "            time.sleep(random.uniform(1.5,3.5))\n",
    "        else:\n",
    "            print (\"已存在数据库，跳过抓取\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
